{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mortality Prediction of Heart Failure Patient in Hospital "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading appropriate libraries \n",
    "    * We will load other libraries as & when needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "from scipy.stats import chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Suppress the warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "masterData = pd.read_excel(\"Healthcare_cat_dataset.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdf = masterData.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1177, 53)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>ID</th>\n",
       "      <th>outcome</th>\n",
       "      <th>age</th>\n",
       "      <th>gendera</th>\n",
       "      <th>BMI_cat</th>\n",
       "      <th>hypertensive</th>\n",
       "      <th>atrialfibrillation</th>\n",
       "      <th>CHD with no MI</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>...</th>\n",
       "      <th>cal_cat</th>\n",
       "      <th>chloride_cat</th>\n",
       "      <th>anion_cat</th>\n",
       "      <th>Mag_cat</th>\n",
       "      <th>ph_cat</th>\n",
       "      <th>Biccarbon_cat</th>\n",
       "      <th>metcat</th>\n",
       "      <th>lactic_cat</th>\n",
       "      <th>pco2_cat</th>\n",
       "      <th>ef_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>125047</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>139812</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>109787</td>\n",
       "      <td>0.0</td>\n",
       "      <td>83</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>130587</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>138290</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   group      ID  outcome  age  gendera  BMI_cat  hypertensive  \\\n",
       "0      1  125047      0.0   72        1        0             0   \n",
       "1      1  139812      0.0   75        2        0             0   \n",
       "2      1  109787      0.0   83        2        1             0   \n",
       "3      1  130587      0.0   43        2        0             0   \n",
       "4      1  138290      0.0   75        2        0             1   \n",
       "\n",
       "   atrialfibrillation  CHD with no MI  diabetes  ...  cal_cat  chloride_cat  \\\n",
       "0                   0               0         1  ...        0             0   \n",
       "1                   0               0         0  ...        0             1   \n",
       "2                   0               0         0  ...        0             1   \n",
       "3                   0               0         0  ...        1             0   \n",
       "4                   0               0         0  ...        1             1   \n",
       "\n",
       "   anion_cat  Mag_cat  ph_cat  Biccarbon_cat  metcat  lactic_cat  pco2_cat  \\\n",
       "0          1        0       1              0       0           0         1   \n",
       "1          1        1       1              0       0           0         0   \n",
       "2          1        1       1              0       0           0         0   \n",
       "3          1        1       1              0       0           0         0   \n",
       "4          1        0       1              0       0           0         0   \n",
       "\n",
       "   ef_cat  \n",
       "0       1  \n",
       "1       1  \n",
       "2       0  \n",
       "3       1  \n",
       "4       1  \n",
       "\n",
       "[5 rows x 53 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdf.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Description\n",
    "\n",
    "Rows: 1176\n",
    "\n",
    "Columns: 53\n",
    "\n",
    "Dependent Variable: outcome\n",
    "\n",
    "Except for Age all are in binary data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependent Variable:- output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdf = mdf[~mdf['outcome'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdf['outcome'] = mdf['outcome'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Droping non significant variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdf = pd.get_dummies(mdf, columns = ['gendera'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdf = mdf.drop(['ID','group'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for Null Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "outcome            1\n",
       "Pulse rate cat    16\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd = mdf.isnull().sum()\n",
    "dd[dd > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputing data using mode as data is binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdf[\"Pulse rate cat\"].fillna(mdf[\"Pulse rate cat\"].mode()[0],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    1017\n",
       "1.0     159\n",
       "Name: outcome, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdf['outcome'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['outcome', 'age', 'BMI_cat', 'hypertensive', 'atrialfibrillation',\n",
       "       'CHD with no MI', 'diabetes', 'deficiencyanemias', 'depression',\n",
       "       'Hyperlipemia', 'Renal failure', 'COPD', 'heart rate at',\n",
       "       'Pulse rate cat', 'Sys_cat', 'Diastolic', 'respiratory cat', 'temp_cat',\n",
       "       'SP O2 ', 'urine_cat', 'hemocrit_cat', 'RBC_Cat', 'mch_cat', 'mchc_Cat',\n",
       "       'mcv_cta', 'rdw_cat', 'leukocytes_cat', 'platelets_cat',\n",
       "       'neutriphil_cat', 'Basophil_cat', 'Lympho_cat', 'PT_cat(sec)',\n",
       "       'INR_cat', 'NT_cat', 'CK_cat', 'Creatinine_cat', 'UN_cat', 'Glu_cat',\n",
       "       'potas_cat', 'sodium_cat', 'cal_cat', 'chloride_cat', 'anion_cat',\n",
       "       'Mag_cat', 'ph_cat', 'Biccarbon_cat', 'metcat', 'lactic_cat',\n",
       "       'pco2_cat', 'ef_cat', 'gendera_1', 'gendera_2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdf.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Defined Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PerformHypothesisTest(dependentVariable, independentVariables):\n",
    "    \n",
    "    evalResult = pd.DataFrame(columns = ['Feature', 'p_Value_Chi'])\n",
    "\n",
    "    for col in independentVariables:\n",
    "        resultTable=pd.crosstab(mdf[col], mdf[dependentVariable])\n",
    "        observedValues = resultTable.values\n",
    "        \n",
    "        val = stats.chi2_contingency(resultTable)\n",
    "        \n",
    "        expectedValues = val[3]\n",
    "        \n",
    "        no_of_rows = len(resultTable.iloc[0:2,0])\n",
    "        no_of_columns = len(resultTable.iloc[0,0:2])\n",
    "        ddof = (no_of_rows - 1) * (no_of_columns - 1)\n",
    "        alpha = 0.05\n",
    "        \n",
    "        chi_square = sum([(o-e)**2./e for o,e in zip(observedValues, expectedValues)])\n",
    "        chi_square_statistic = chi_square[0] + chi_square[1]\n",
    "        \n",
    "        p_value_Chi = 1 - chi2.cdf(x = chi_square_statistic, df = ddof)\n",
    "        \n",
    "        significant_Chi = \"\"\n",
    "        \n",
    "        significant_t = \"\"\n",
    "        \n",
    "        if p_value_Chi <= alpha:\n",
    "            significant_Chi = \"Yes\"\n",
    "        else:\n",
    "            significant_Chi = \"No\"\n",
    "        \n",
    "        evalResult = evalResult.append({'Feature' : col, \n",
    "                                        'p_Value_Chi' : p_value_Chi,\n",
    "                                        'significant_Chi':significant_Chi\n",
    "                                       }, ignore_index = True)\n",
    "    \n",
    "    \n",
    "    return evalResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def with_hue(ax, feature, Number_of_categories, hue_categories):\n",
    "    a = [p.get_height() for p in ax.patches]\n",
    "    patch = [p for p in ax.patches]\n",
    "    for i in range(Number_of_categories):\n",
    "        total = feature.value_counts().values[i]\n",
    "        for j in range(hue_categories):\n",
    "            percentage = '{:.1f}%'.format(100 * a[(j*Number_of_categories + i)]/total)\n",
    "            x = patch[(j*Number_of_categories + i)].get_x() + patch[(j*Number_of_categories + i)].get_width() / 2 - 0.15\n",
    "            y = patch[(j*Number_of_categories + i)].get_y() + patch[(j*Number_of_categories + i)].get_height() \n",
    "            h = patch[(j*Number_of_categories + i)].get_height()\n",
    "            w = patch[(j*Number_of_categories + i)].get_width()\n",
    "            x1 = patch[(j*Number_of_categories + i)].get_x()\n",
    "            ax.annotate(percentage, (x1 + w / 2., h),\n",
    "                           ha = 'center', va = 'top', xytext = (0, 12), textcoords = 'offset points')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CalculateValues(df, variable):\n",
    "    results = df.groupby([variable]).outcome.value_counts()\n",
    "    y = [f\"{x/results[0].sum()*100:.0f}\" for x in results[0]]  \n",
    "    text = f\"Alive = {y[0]} % \\nDead = {y[1]} %\\n\"\n",
    "    text1 = f\"\\nH0: There is no impact of {variable} on output \\nH1: There is impact of {variable} on output\\n\"\n",
    "    pValue = evaluationResult[evaluationResult['Feature'] == variable].squeeze()['p_Value_Chi'] \n",
    "    \n",
    "    pValueText = f\"\\np_value for {variable} is {pValue}\\n\"\n",
    "    \n",
    "    conclusionText = \"\"\n",
    "    if pValue > 0.05:\n",
    "        conclusionText = f\"\\nHence we fail to reject the H0\"\n",
    "    else:\n",
    "        conclusionText = f\"\\nHence we reject the H0\"\n",
    "        \n",
    "    vv = r'{ \\textcolor{colorB} {\\bfseries A}}: absquatulate'\n",
    "    text = text + text1 + pValueText + conclusionText\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SetPValues(ax, df, variable):\n",
    "    text = CalculateValues(df, variable)\n",
    "    ax.set_axis_off()\n",
    "    ax.text(0, 0.5, text, fontsize=14,weight=\"bold\");\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SetFeaturesPie(ax, featureCount, variable):\n",
    "    ax.pie(featureCount, \n",
    "                  autopct='%1.1f%%',                  \n",
    "                  explode=(0.025,0.025),  \n",
    "                  colors=['#4F6272', 'navajowhite'],\n",
    "                  labels = ['AN', 'N'],\n",
    "                  rotatelabels=True,\n",
    "                  startangle=80,)\n",
    "    ax.set_title('Feature Ratio', pad=25)\n",
    "    labels = f\"AN = Having {variable} \\nN = Not Having {variable}\"\n",
    "    ax.annotate(labels, xy=(0.9,0.9),xycoords='axes fraction', fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SetOutcomeCountPie(ax, outcomeCount, variable):\n",
    "    ax.pie(outcomeCount, \n",
    "                  autopct='%1.1f%%',                  \n",
    "                  explode=(0.025,0.025),  \n",
    "                  colors=['skyblue', '#B7C3F3'],\n",
    "                  labels = ['AN', 'N'],\n",
    "                  rotatelabels=True,\n",
    "                  startangle=80,)\n",
    "    ax.set_title('Feature Ratio', pad=25)\n",
    "    labels = f\"AN = Having {variable} \\nN = Not Having {variable}\"\n",
    "    ax.annotate(labels, xy=(0.9,0.9),xycoords='axes fraction', fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SetOutcomeCountSNSPlot(ax, df, variable, outcome):\n",
    "    sb.countplot(df[variable], hue=df[outcome],palette=\"PuBu\",ax=ax)\n",
    "    with_hue(ax, df[variable], 2, 2)    \n",
    "    ax.set_title('Outcome Bar', pad=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SetresultsPie(ax, results):\n",
    "    ax.pie(results, \n",
    "                  autopct='%1.1f%%', \n",
    "                  labels = ['AN+A', 'AN+D', 'N+A', 'N+D'],\n",
    "                  explode=(0.025,0.05,0.025,0.05),\n",
    "                  colors=['#3880A8', '#B7C3F3','skyblue','navajowhite'],\n",
    "                  rotatelabels=True,\n",
    "                  startangle=180,)\n",
    "    ax.set_title('Outcome Pie', pad=25)\n",
    "    labels = f\"AN = Abnormal \\nN = Normal \\nA = Alive \\nD = Dead\"\n",
    "    ax.annotate(labels, xy=(0.9,0.9),xycoords='axes fraction', fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_viz(feature='outcome'):\n",
    "    validCol = [feature,'outcome']\n",
    "    corr = mdf[validCol].corr()\n",
    "    \n",
    "    featureCount = mdf[feature].value_counts()\n",
    "    \n",
    "    outcomeCount =mdf[mdf[feature] == 1].outcome.value_counts()\n",
    "    \n",
    "    results = mdf.groupby([feature, 'outcome']).outcome.value_counts()    \n",
    "    \n",
    "# fig, axs = plt.subplots(3, 2, figsize=(18, 18))    \n",
    "    \n",
    "    fig = plt.figure(constrained_layout=True, figsize=(16, 16))\n",
    "    gs = GridSpec(3, 2, height_ratios=[1, 3, 3], figure=fig)\n",
    " \n",
    "    # create sub plots as grid\n",
    "    ax1 = fig.add_subplot(gs[0, :])\n",
    "    ax2 = fig.add_subplot(gs[1, 0])\n",
    "    ax3 = fig.add_subplot(gs[1, 1])\n",
    "    ax4 = fig.add_subplot(gs[2, 0])\n",
    "    ax5 = fig.add_subplot(gs[2, 1])\n",
    "    \n",
    "    fig.suptitle(\"Features Significance Analysis\")    \n",
    "    \n",
    "    SetPValues(ax1, mdf, feature)    \n",
    "    \n",
    "    SetFeaturesPie(ax2, featureCount, feature)\n",
    "    \n",
    "    SetOutcomeCountPie(ax3, outcomeCount, feature)    \n",
    "\n",
    "    SetOutcomeCountSNSPlot(ax4, mdf, feature, 'outcome')\n",
    "    \n",
    "    SetresultsPie(ax5, results)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualization w.r.t Dependent Vatiable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from matplotlib.gridspec import GridSpec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e45c5fbd5e64b89839bb64141148378",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='feature', options=('BMI_cat', 'hypertensive', 'atrialfibrillation'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Display the charts with Dropdown \n",
    "\n",
    "xDataset = mdf.drop(['outcome','age'], axis=1)\n",
    "\n",
    "independentVariables = xDataset.columns\n",
    "\n",
    "evaluationResult = PerformHypothesisTest('outcome', independentVariables)\n",
    "\n",
    "widgets.interact(plot_viz, feature=independentVariables);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Derive new Features if need be "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add column for anemia & blood pressure\n",
    "# mdf['derivedAnemia'] = np.where((((mdf['deficiencyanemias'] == 1) & (mdf['RBC_Cat'] == 1)) \n",
    "#                                  | ((mdf['deficiencyanemias'] == 0) & (mdf['RBC_Cat'] == 1))), 1, 0)\n",
    "\n",
    "mdf['derivedAnemia'] = np.where((mdf['deficiencyanemias'] == 1) & (mdf['RBC_Cat'] == 1), 1, 0)\n",
    "\n",
    "mdf['derivedInflammation'] = np.where((mdf['neutriphil_cat'] == 1) & (mdf['Lympho_cat'] == 1), 1, 0)  \n",
    "\n",
    "independentVariables = ['derivedAnemia', 'deficiencyanemias', 'RBC_Cat', 'derivedInflammation', 'neutriphil_cat', 'Lympho_cat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluationResult = PerformHypothesisTest('outcome', independentVariables)\n",
    "evaluationResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot p-Values \n",
    "xDataset = mdf.drop('outcome', axis=1)\n",
    "\n",
    "evaluationResult = PerformHypothesisTest('outcome', xDataset.columns)\n",
    "\n",
    "evaluationResult = evaluationResult.sort_values(['p_Value_Chi'], ascending=True)\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [8,10]\n",
    "\n",
    "colors = [\"red\" if i > 0.05 else \"#40A944\" for i in evaluationResult.p_Value_Chi]\n",
    "\n",
    "plt.barh(evaluationResult.Feature, evaluationResult.p_Value_Chi, color = colors)\n",
    " \n",
    "# setting label of y-axis\n",
    "plt.ylabel(\"Features\")\n",
    " \n",
    "# setting label of x-axis\n",
    "plt.xlabel(\"p-Values\")\n",
    "plt.title(\"Horizontal bar graph\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluationResult"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treating Imbalanced Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdf['outcome'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "over = SMOTE(sampling_strategy=1, random_state=42)\n",
    "under = RandomUnderSampler(sampling_strategy=1, random_state=42)\n",
    "steps = [('o', over), ('u', under)]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "# transform the dataset\n",
    "X, y = pipeline.fit_resample(mdf.drop('outcome', axis=1), mdf['outcome'])\n",
    "mdf_upsampled = pd.concat([pd.DataFrame(y), pd.DataFrame(X)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdf_upsampled['outcome'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling with different Algos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, recall_score, roc_auc_score, precision_score, f1_score\n",
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from preventing overfitting we will do seperate data into train and test\n",
    "\n",
    "y = mdf_upsampled['outcome']\n",
    "X = mdf_upsampled.drop(columns = [\"outcome\"], axis = 1)\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X, y,test_size = 0.3,random_state = 9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_logReg = LogisticRegression()\n",
    "res = model_logReg.fit(X_train, y_train)\n",
    "pred= model_logReg.predict(X_test)\n",
    "pred_logi = model_logReg.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD = 0.5\n",
    "y_pred_logi = np.where(model_logReg.predict_proba(X_test)[:,1] > THRESHOLD, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logiDF = pd.DataFrame(data=[accuracy_score(y_test, y_pred_logi), recall_score(y_test, y_pred_logi),\n",
    "                   precision_score(y_test, y_pred_logi), f1_score(y_test, y_pred_logi, average='binary'),\n",
    "                   roc_auc_score(y_test, y_pred_logi)], \n",
    "             index=[\"accuracy\", \"recall\", \"precision\", \"f1_score\", \"roc_auc_score\"])\n",
    "\n",
    "logiDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn= KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train,y_train)\n",
    "y_pred_knn= knn.predict(X_test)\n",
    "pred_knn = knn.predict_proba(X_test)\n",
    "\n",
    "pd.DataFrame(data=[accuracy_score(y_test, y_pred_knn), recall_score(y_test, y_pred_knn),\n",
    "                   precision_score(y_test, y_pred_knn),  f1_score(y_test, y_pred_knn, average='binary'),\n",
    "                   roc_auc_score(y_test, y_pred_knn)], \n",
    "             index=[\"accuracy\", \"recall\", \"precision\", \"f1_score\", \"roc_auc_score\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree = DecisionTreeClassifier()\n",
    "dtree.fit(X_train,y_train)\n",
    "\n",
    "y_pred_dtree = dtree.predict(X_test)\n",
    "pred_dtree = dtree.predict_proba(X_test)\n",
    "\n",
    "pd.DataFrame(data=[accuracy_score(y_test, y_pred_dtree), recall_score(y_test, y_pred_dtree),\n",
    "                   precision_score(y_test, y_pred_dtree),  f1_score(y_test, y_pred_dtree, average='binary'),\n",
    "                   roc_auc_score(y_test, y_pred_dtree)], \n",
    "             index=[\"accuracy\", \"recall\", \"precision\", \"f1_score\", \"roc_auc_score\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM ( Support Vector Machine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svclassifier = SVC(kernel='linear', probability=True)\n",
    "svclassifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_svm = svclassifier.predict(X_test)\n",
    "pred_svm = svclassifier.predict_proba(X_test)\n",
    "\n",
    "pd.DataFrame(data=[accuracy_score(y_test, y_pred_svm), recall_score(y_test, y_pred_svm),\n",
    "                   precision_score(y_test, y_pred_svm),  f1_score(y_test, y_pred_svm, average='binary'),\n",
    "                   roc_auc_score(y_test, y_pred_svm)], \n",
    "             index=[\"accuracy\", \"recall\", \"precision\", \"f1_score\", \"roc_auc_score\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rforestClassifier = RandomForestClassifier(n_estimators = 100)\n",
    "rforestClassifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred_rf = rforestClassifier.predict(X_test)\n",
    "pred_rf = rforestClassifier.predict_proba(X_test)\n",
    "\n",
    "pd.DataFrame(data=[accuracy_score(y_test, y_pred_rf), recall_score(y_test, y_pred_rf),\n",
    "                   precision_score(y_test, y_pred_rf),  f1_score(y_test, y_pred_rf, average='binary'),\n",
    "                   roc_auc_score(y_test, y_pred_rf)], \n",
    "             index=[\"accuracy\", \"recall\", \"precision\", \"f1_score\", \"roc_auc_score\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XG Boost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbClassifier = XGBClassifier()\n",
    "xgbClassifier.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred_xgb = xgbClassifier.predict(X_test)\n",
    "pred_xgb = xgbClassifier.predict_proba(X_test)\n",
    "\n",
    "pd.DataFrame(data=[accuracy_score(y_test, y_pred_xgb), recall_score(y_test, y_pred_xgb),\n",
    "                   precision_score(y_test, y_pred_xgb),  f1_score(y_test, y_pred_xgb, average='binary'),\n",
    "                   roc_auc_score(y_test, y_pred_xgb)], \n",
    "             index=[\"accuracy\", \"recall\", \"precision\", \"f1_score\", \"roc_auc_score\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models Evaluation using ROC Curve Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# roc curve for models\n",
    "fpr1, tpr1, thresh1 = roc_curve(y_test, pred_logi[:,1], pos_label=1)\n",
    "fpr2, tpr2, thresh2 = roc_curve(y_test, pred_knn[:,1], pos_label=1)\n",
    "fpr3, tpr3, thresh3 = roc_curve(y_test, pred_dtree[:,1], pos_label=1)\n",
    "fpr4, tpr4, thresh4 = roc_curve(y_test, pred_svm[:,1], pos_label=1)\n",
    "fpr5, tpr5, thresh5 = roc_curve(y_test, pred_rf[:,1], pos_label=1)\n",
    "fpr6, tpr6, thresh6 = roc_curve(y_test, pred_xgb[:,1], pos_label=1)\n",
    "\n",
    "# roc curve for tpr = fpr \n",
    "random_probs = [0 for i in range(len(y_test))]\n",
    "p_fpr, p_tpr, _ = roc_curve(y_test, random_probs, pos_label=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn')\n",
    "\n",
    "# plot roc curves\n",
    "plt.plot(fpr1, tpr1, linestyle='--',color='orange', label='Logistic Regression')\n",
    "plt.plot(fpr2, tpr2, linestyle='solid',color='green', label='KNN')\n",
    "plt.plot(fpr3, tpr3, linestyle='dashed',color='red', label='DTree')\n",
    "plt.plot(fpr4, tpr4, linestyle='solid',color='brown', label='SVM')\n",
    "plt.plot(fpr5, tpr5, linestyle='dashdot',color='black', label='RF')\n",
    "plt.plot(fpr6, tpr6, linestyle='-.',color='blue', label='XGB')\n",
    "plt.plot(p_fpr, p_tpr, linestyle='-', color='pink')\n",
    "# title\n",
    "plt.title('ROC curve')\n",
    "# x label\n",
    "plt.xlabel('False Positive Rate')\n",
    "# y label\n",
    "plt.ylabel('True Positive rate')\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.savefig('ROC',dpi=300)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from matplotlib import pyplot "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chi2 Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "evaluationResult = PerformHypothesisTest('outcome', X_train.columns)\n",
    "ns_df_sorted = evaluationResult.sort_values(['p_Value_Chi'], ascending = True).head(15)\n",
    "ns_df_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K Best Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_significant_columns = SelectKBest(mutual_info_classif,k= 15)\n",
    "sel_significant_columns.fit(X_train,y_train)\n",
    "\n",
    "names = X_train.columns.values[sel_significant_columns.get_support()]\n",
    "scores = sel_significant_columns.scores_[sel_significant_columns.get_support()]\n",
    "names_scores = list(zip(names, scores))\n",
    "ns_df = pd.DataFrame(data = names_scores, columns=['Feat_names', 'F_Scores'])\n",
    "#Sort the dataframe for better visualization\n",
    "ns_df_sorted = ns_df.sort_values(['F_Scores', 'Feat_names'], ascending = [False, True])\n",
    "ns_df_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,8))\n",
    "ns_df_sorted.plot(kind='bar')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ExtraTree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_tree_forest = ExtraTreesClassifier(n_estimators = 100, criterion ='gini', max_features = 15)\n",
    "extra_tree_forest.fit(X, y)\n",
    "\n",
    "feature_importance = extra_tree_forest.feature_importances_\n",
    "\n",
    "\n",
    "feature_importance_normalized = np.std([tree.feature_importances_ \n",
    "                                        for tree in extra_tree_forest.estimators_],\n",
    "                                        axis = 0)\n",
    "features = pd.Series(feature_importance_normalized, index=X.columns).nlargest(15)\n",
    "\n",
    "etf_features = pd.DataFrame(features)\n",
    "\n",
    "etf_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recursive Feature selection "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg_rfe_model = RFE(estimator=logreg,n_features_to_select=15)\n",
    "logreg_model_fit = logreg_rfe_model.fit(X_train,y_train)\n",
    "logreg_feat_index = pd.Series(data = logreg_model_fit.ranking_, index = X_train.columns)\n",
    "logreg_feat_rfe = logreg_feat_index[logreg_feat_index==1].index\n",
    "\n",
    "logreg_selected_features = pd.DataFrame(logreg_feat_rfe)\n",
    "logreg_selected_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_lin=SVC(kernel='linear')\n",
    "svm_rfe_model=RFE(estimator=svm_lin,n_features_to_select=15)\n",
    "svm_rfe_model_fit=svm_rfe_model.fit(X_train,y_train)\n",
    "feat_index = pd.Series(data = svm_rfe_model_fit.ranking_, index = X_train.columns)\n",
    "signi_feat_rfe = feat_index[feat_index==1].index\n",
    "\n",
    "svm_selected_features = pd.DataFrame(signi_feat_rfe)\n",
    "svm_selected_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators = 100)\n",
    "clf_rfe_model=RFE(estimator=clf,n_features_to_select=15)\n",
    "clf_model_fit=clf_rfe_model.fit(X_train,y_train)\n",
    "feat_index = pd.Series(data = clf_model_fit.ranking_, index = X_train.columns)\n",
    "signi_feat_rfe = feat_index[feat_index==1].index\n",
    "\n",
    "rf_selected_features = pd.DataFrame(signi_feat_rfe)\n",
    "rf_selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
